{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "076b95fb",
   "metadata": {},
   "source": [
    "# Spam Classifier with Apache SpamAssassin Dataset\n",
    "\n",
    "In this project, I build a basic spam classifier using raw email files from the [Apache SpamAssassin public corpus](https://spamassassin.apache.org/old/publiccorpus/).\n",
    "\n",
    "The goal is to:\n",
    "- Parse and preprocess raw email data\n",
    "- Convert email text into a usable feature vector\n",
    "- Train and evaluate spam classification models\n",
    "\n",
    "This notebook represents a learning exercise in working with real-world, unstructured text data. It involves:\n",
    "- Reading raw `.txt` email files (not CSVs)\n",
    "- Extracting useful content from headers and body\n",
    "- Building a feature extraction pipeline from scratch\n",
    "- Training multiple classifiers (e.g., Logistic Regression, Naive Bayes)\n",
    "\n",
    "### Dataset Used:\n",
    "- `20030228_easy_ham.tar.bz2`: ~2,500 ham (non-spam) emails\n",
    "- `20030228_spam.tar.bz2`: ~500 spam emails"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3552f1d9",
   "metadata": {},
   "source": [
    "\n",
    "Let’s get started by inspecting the contents of a sample email.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45d613c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from email import policy\n",
    "from email.parser import BytesParser\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37ada4d",
   "metadata": {},
   "source": [
    "## 1. Exploring the Raw Emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd6cfded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Date:        Wed, 21 Aug 2002 10:54:46 -0500\n",
      "    From:        Chris Garrigues <cwg-dated-1030377287.06fa6d@DeepEddy.Com>\n",
      "    Message-ID:  <1029945287.4797.TMDA@deepeddy.vircio.com>\n",
      "\n",
      "\n",
      "  | I can't reproduce this error.\n",
      "\n",
      "For me it is very repeatable... (like every time, without fail).\n",
      "\n",
      "This is the debug log of the pick happening ...\n",
      "\n",
      "18:19:03 Pick_It {exec pick +inbox -list -lbrace -lbrace -subject ftp -rbrace -rbrace} {4852-4852 -sequence mercury}\n",
      "18:19:03 exec pick +inbox -list -lbrace -lbrac\n"
     ]
    }
   ],
   "source": [
    "def extract_body(file_path):\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        msg = BytesParser(policy=policy.default).parse(f)\n",
    "\n",
    "    def safe_get_content(part):\n",
    "        try:\n",
    "            return part.get_content()\n",
    "        except LookupError:\n",
    "            # Fallback if encoding is invalid or unknown\n",
    "            raw = part.get_payload(decode=True)\n",
    "            return raw.decode(\"utf-8\", errors=\"replace\") if raw else \"\"\n",
    "\n",
    "    if msg.is_multipart():\n",
    "        body = msg.get_body(preferencelist=(\"plain\",))\n",
    "        return safe_get_content(body) if body else \"\"\n",
    "    else:\n",
    "        return safe_get_content(msg)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "file_path = os.path.join(\"ham\", os.listdir(\"ham\")[0])\n",
    "body = extract_body(file_path)\n",
    "print(body[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35598b8",
   "metadata": {},
   "source": [
    "**The body still has the parts of header from likely Forwarded message including headers (From, Date, etc.) Quoted text, signatures, or email footers. We will make a helper function to extract the body from it**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6271ef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "| I can't reproduce this error.\n",
      "\n",
      "For me it is very repeatable... (like every time, without fail).\n",
      "\n",
      "This is the debug log of the pick happening ...\n",
      "\n",
      "18:19:03 Pick_It {exec pick +inbox -list -lbrace -lbrace -subject ftp -rbrace -rbrace} {4852-4852 -sequence mercury}\n",
      "18:19:03 exec pick +inbox -list -lbrace -lbrace -subject ftp -rbrace -rbrace 4852-4852 -sequence mercury\n",
      "18:19:04 Ftoc_PickMsgs {{1 hit}}\n",
      "18:19:04 Marking 1 hits\n",
      "18:19:04 tkerror: syntax error in expression \"int ...\n",
      "\n",
      "Note, if I run t\n"
     ]
    }
   ],
   "source": [
    "def strip_leading_headers(text):\n",
    "    lines = text.splitlines()\n",
    "    lines = [line.strip() for line in lines]\n",
    "    cleaned_body = []\n",
    "    header_pattern = r\"^[A-Za-z\\-]+:\\s\"\n",
    "    for line in lines:\n",
    "        if re.match(header_pattern, line):\n",
    "            continue\n",
    "        else:\n",
    "            cleaned_body.append(line)\n",
    "\n",
    "    return \"\\n\".join(cleaned_body)\n",
    "\n",
    "print(strip_leading_headers(body)[:500])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0360187a",
   "metadata": {},
   "source": [
    "**Email cleaning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f6f242d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_email_text(text):\n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # Remove email quotes (lines starting with > or |)\n",
    "    text = \"\\n\".join(line for line in text.splitlines() if not re.match(r\"^(>|\\|)\", line))\n",
    "\n",
    "    # Remove URLs\n",
    "    text = re.sub(r\"https?://\\S+|www\\.\\S+\", \"URL\", text)\n",
    "\n",
    "    # Remove email addresses\n",
    "    text = re.sub(r\"\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Za-z]{2,}\\b\", \"EMAIL\", text)\n",
    "\n",
    "    # Remove special characters/punctuation\n",
    "    text = re.sub(r\"[^a-z0-9\\s]\", \" \", text)\n",
    "\n",
    "    # Remove extra whitespace\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fdc31c3",
   "metadata": {},
   "source": [
    "### We will apply the above functions to all the emails and save it with their respective labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47377861",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_folder(folder_name, label):\n",
    "    \n",
    "    data = []\n",
    "    for filename in os.listdir(folder_name):\n",
    "        file_path = os.path.join(folder_name, filename)\n",
    "        try:\n",
    "            raw_body = extract_body(file_path)\n",
    "            stripped_body = strip_leading_headers(raw_body)\n",
    "            clean_body = clean_email_text(stripped_body)\n",
    "            data.append((clean_body, label))\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {filename}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "301cfcab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total emails processed: 3002\n"
     ]
    }
   ],
   "source": [
    "ham_data = process_folder(\"ham\", label=0)\n",
    "spam_data = process_folder(\"spam\", label=1)\n",
    "\n",
    "all_emails = ham_data + spam_data\n",
    "\n",
    "print(f\"Total emails processed: {len(all_emails)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e56eca7",
   "metadata": {},
   "source": [
    "## Seperating data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47252785",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts, labels = zip(*all_emails)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(texts, labels, random_state=42, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b56e17",
   "metadata": {},
   "source": [
    "## Feature Vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2578693f",
   "metadata": {},
   "source": [
    "After splitting our emails into training and test sets, the next step is to **convert the text data into numbers** that machine learning models can understand.\n",
    "\n",
    "We’ll use a technique called **feature vectorization** which:\n",
    "\n",
    "- Builds a vocabulary of all words in the training emails\n",
    "- Represents each email as a vector showing how often each word appears (or simply if it appears)\n",
    "- This vectorized data can then be fed into classifiers to learn patterns and predict spam or ham\n",
    "\n",
    "Think of it as translating human language into a numerical format the machine can work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16d4aed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "\n",
    "X_test_vec = vectorizer.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840895ec",
   "metadata": {},
   "source": [
    "## Fitting it to the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19ec4cd",
   "metadata": {},
   "source": [
    "When building our spam classifier, we will use a **pipeline** that combines the text vectorization step (`CountVectorizer`) with the classification model (e.g., Logistic Regression).\n",
    "\n",
    "**Why?**\n",
    "\n",
    "- To ensure the vectorizer is **fit only on the training data** during cross-validation or train-test split.\n",
    "- Prevents **data leakage** — where information from the test data accidentally influences the training process.\n",
    "- Guarantees that transformations are applied consistently and correctly during training and testing.\n",
    "- Simplifies code by chaining preprocessing and model training into one step.\n",
    "\n",
    "Using a pipeline is a best practice to maintain the integrity of model evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "586344ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation accuracy scores: [0.98002497 0.96625    0.97375   ]\n",
      "Mean accuracy: 0.9733416562630045\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    (\"counter_vectorizer\", CountVectorizer()),\n",
    "    (\"log_reg\", LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "scores = cross_val_score(pipeline, X_train, y_train, cv=3, scoring=\"accuracy\")\n",
    "print(\"Cross-validation accuracy scores:\", scores)\n",
    "print(\"Mean accuracy:\", scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9684d8b2",
   "metadata": {},
   "source": [
    "When classes are imbalanced (e.g., way more ham than spam emails), accuracy alone can be misleading. We will calculate the **f1_score** and **confusion matrix** to evaluate the model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "093dfeed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1997    7]\n",
      " [  57  340]]\n",
      "Precision score : 0.9798 \n",
      "Recall score : 0.8564 \n",
      "f1_score: 0.9140\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = cross_val_predict(pipeline, X_train, y_train, cv=3)\n",
    "conf_mx = confusion_matrix(y_train, y_train_pred)\n",
    "print(conf_mx)\n",
    "print(f\"Precision score : {precision_score(y_train, y_train_pred):.4f} \\nRecall score : {recall_score(y_train, y_train_pred):.4f} \\nf1_score: {f1_score(y_train, y_train_pred):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56b8566",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
